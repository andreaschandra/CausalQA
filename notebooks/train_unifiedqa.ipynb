{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51efeeb6",
   "metadata": {},
   "source": [
    "# Train UnifiedQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e370b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import Namespace\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5325a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate question+context with \\\\n as a separator\n",
    "def build_input(batch):\n",
    "    input_ = [\n",
    "        (question + \" \\\\n \" + context if context is not None else question)\n",
    "        for question, context in zip(\n",
    "            batch[\"question_processed\"], batch[\"context_processed\"]\n",
    "        )\n",
    "    ]\n",
    "    batch[\"input\"] = input_\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3e6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unifiedqa(args: argparse.ArgumentParser):\n",
    "    set_seed(args.seed)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(args.checkpoint)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(args.checkpoint)\n",
    "\n",
    "    def tokenize_function_train(batches):\n",
    "        encoded_inputs = tokenizer(\n",
    "            batches[\"input\"],\n",
    "            max_length=args.source_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoded_answers = tokenizer(\n",
    "            batches[\"answer\"],\n",
    "            max_length=args.target_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoded_inputs[\"labels\"] = [\n",
    "            [(a if a != tokenizer.pad_token_id else -100) for a in ans]\n",
    "            for ans in encoded_answers[\"input_ids\"]\n",
    "        ]\n",
    "        return encoded_inputs\n",
    "\n",
    "    train_dataset = load_dataset(\"csv\", data_files=args.train_file)[\"train\"]\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        build_input, batched=True, load_from_cache_file=False, num_proc=args.num_procs\n",
    "    )\n",
    "    train_dataset = train_dataset.remove_columns([\"context\", \"context_processed\"])\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_function_train,\n",
    "        batched=True,\n",
    "        load_from_cache_file=False,\n",
    "        num_proc=args.num_procs,\n",
    "    )\n",
    "    train_dataset = train_dataset.remove_columns([\"input\", \"answer\"])\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    log_steps = args.steps // 10\n",
    "\n",
    "    train_args = Seq2SeqTrainingArguments(\n",
    "        \"models\",\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        max_steps=args.steps,\n",
    "        seed=args.seed,\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=log_steps,\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_dataset,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    _ = trainer.train()\n",
    "\n",
    "    start_index = args.train_file.rfind(\"/\") + 1\n",
    "    end_index = args.train_file.find(\"_\")\n",
    "    trainer.save_model(args.output_directory + args.train_file[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ee26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    checkpoint=\"allenai/unifiedqa-v2-t5-base-1363200\",\n",
    "    train_file=\"Webis-CausalQA-22-v-1.0/input/original-splits/squad2_train_original_split.csv\",\n",
    "    steps=6000,\n",
    "    source_length=2048,\n",
    "    target_length=100,\n",
    "    batch_size=2,\n",
    "    seed=42,\n",
    "    num_procs=8,\n",
    "    output_directory=\"models/original-splits/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e74ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
