{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2adfde-e9f6-4853-a663-61f976daaf8e",
   "metadata": {},
   "source": [
    "# Train UnifiedQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9ebe59-5324-4b13-8d67-70cad62432a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25fc46-9723-4562-ab7f-fefe913a58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint\",\n",
    "        type=str,\n",
    "        default=\"allenai/unifiedqa-v2-t5-base-1363200\",\n",
    "        help=\"Checkpoint to start fine-tuning from.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_file\",\n",
    "        type=str,\n",
    "        default=\"Webis-CausalQA-22-v-1.0/input/original-splits/squad2_train_original_split.csv\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--steps\", type=int, default=6000, help=\"Number of train steps.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--source_length\",\n",
    "        type=int,\n",
    "        default=2048,\n",
    "        help=\"Maximum length of the input sequences (question + context).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--target_length\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"Maximum length of the output sequences.\",\n",
    "    )\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\n",
    "        \"--num_procs\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Number of processes for dataset loading.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_directory\", type=str, default=\"models/original-splits/\"\n",
    "    )\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b408ed3-7651-4ea9-9f10-44124621f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate question+context with \\\\n as a separator\n",
    "def build_input(batch):\n",
    "    input_ = [\n",
    "        (question + \" \\\\n \" + context if context is not None else question)\n",
    "        for question, context in zip(\n",
    "            batch[\"question_processed\"], batch[\"context_processed\"]\n",
    "        )\n",
    "    ]\n",
    "    batch[\"input\"] = input_\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed4a94-3f93-4bca-97cf-7befb21cd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unifiedqa(args: argparse.ArgumentParser):\n",
    "    set_seed(args.seed)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(args.checkpoint)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(args.checkpoint)\n",
    "\n",
    "    def tokenize_function_train(batches):\n",
    "        encoded_inputs = tokenizer(\n",
    "            batches[\"input\"],\n",
    "            max_length=args.source_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoded_answers = tokenizer(\n",
    "            batches[\"answer\"],\n",
    "            max_length=args.target_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoded_inputs[\"labels\"] = [\n",
    "            [(a if a != tokenizer.pad_token_id else -100) for a in ans]\n",
    "            for ans in encoded_answers[\"input_ids\"]\n",
    "        ]\n",
    "        return encoded_inputs\n",
    "\n",
    "    train_dataset = load_dataset(\"csv\", data_files=args.train_file)[\"train\"]\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        build_input, batched=True, load_from_cache_file=False, num_proc=args.num_procs\n",
    "    )\n",
    "    train_dataset = train_dataset.remove_columns([\"context\", \"context_processed\"])\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_function_train,\n",
    "        batched=True,\n",
    "        load_from_cache_file=False,\n",
    "        num_proc=args.num_procs,\n",
    "    )\n",
    "    train_dataset = train_dataset.remove_columns([\"input\", \"answer\"])\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    log_steps = args.steps // 10\n",
    "\n",
    "    train_args = Seq2SeqTrainingArguments(\n",
    "        \"models\",\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        max_steps=args.steps,\n",
    "        seed=args.seed,\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=log_steps,\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_dataset,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    _ = trainer.train()\n",
    "\n",
    "    start_index = args.train_file.rfind(\"/\") + 1\n",
    "    end_index = args.train_file.find(\"_\")\n",
    "    trainer.save_model(args.output_directory + args.train_file[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13c254-00bb-4bb3-9413-11802aa8b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_unifiedqa(parse_args())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
